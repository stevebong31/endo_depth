{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob, cv2, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras import applications, optimizers, losses, layers\n",
    "from tensorflow.keras.layers import Input, concatenate, Dense, LeakyReLU, UpSampling2D, SeparableConv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramdom_seed = 4885\n",
    "tf.random.set_random_seed(ramdom_seed)\n",
    "np.random.seed(ramdom_seed)\n",
    "random.seed(ramdom_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image_colorspace(image):\n",
    "    # input shape [h, w * seq , c]\n",
    "    random_gamma = random.uniform(0.8,1.2)\n",
    "    random_brightness = random.uniform(0.5, 2.0)\n",
    "    random_colors = [random.uniform(0.8,1.2), random.uniform(0.8,1.2), random.uniform(0.8,1.2)]\n",
    "    # Randomly shift gamma.\n",
    "    image_aug = image**random_gamma\n",
    "    # Randomly shift brightness. \n",
    "    image_aug *= random_brightness\n",
    "    # Randomly shift color. \n",
    "    white = np.ones([image.shape[0], image.shape[1]])\n",
    "    color_image = np.stack([white * random_colors[i] for i in range(3)], axis=2)\n",
    "    image_aug *= color_image\n",
    "    # Saturate.\n",
    "    image_aug = np.clip(image_aug, 0, 1)\n",
    "    return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data_path, batch, aug):\n",
    "    dir_list = os.listdir(data_path)\n",
    "    img_list = []\n",
    "    for j in dir_list:\n",
    "        img_path = os.path.join(data_path, j)\n",
    "        tmp_list = sorted(glob.glob(img_path +'/*.png'))\n",
    "        img_list += tmp_list\n",
    "    idx = 0\n",
    "    while 1:\n",
    "        idx_list = list(range(0,len(img_list)))\n",
    "        random.shuffle(idx_list)\n",
    "        bat_img = []\n",
    "        bat_lab = []\n",
    "        if idx > len(idx_list) - batch:\n",
    "            idx = idx_list[idx:]\n",
    "            idx = 0\n",
    "        else:\n",
    "            tmp_list = idx_list[idx:idx+batch]\n",
    "            idx = idx + batch\n",
    "            \n",
    "        for i in tmp_list:\n",
    "            img_tmp = cv2.imread(img_list[i])\n",
    "            \n",
    "            if img_tmp is None:\n",
    "                print(img_list[i])\n",
    "            if aug == 1:    \n",
    "                img = augment_image_colorspace(cv2.cvtColor(img_tmp[:,:256,:],cv2.COLOR_BGR2RGB)/255.)\n",
    "            else:\n",
    "                img = cv2.cvtColor(img_tmp[:,:256,:],cv2.COLOR_BGR2RGB)/255.\n",
    "            lab = cv2.cvtColor(img_tmp[:,256:,:], cv2.COLOR_BGR2GRAY)/255.\n",
    "            bat_img.append(img)\n",
    "            bat_lab.append(lab) \n",
    "        yield np.array(bat_img), [np.expand_dims(np.array([cv2.resize(i, (256, 256)) for i in bat_lab]),axis = -1),\n",
    "                                 np.expand_dims(np.array([cv2.resize(i, (128, 128)) for i in bat_lab]),axis = -1),\n",
    "                                 np.expand_dims(np.array([cv2.resize(i, (64, 64)) for i in bat_lab]),axis = -1),\n",
    "                                 np.expand_dims(np.array([cv2.resize(i, (32, 32)) for i in bat_lab]),axis = -1),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(inputs):\n",
    "    conv1 = Conv2D(64, 7, padding = 'same', strides=(2, 2), activation = 'relu')(inputs)\n",
    "    conv2 = Conv2D(128, 5,  padding = 'same', strides=(2, 2), activation = 'relu')(conv1)\n",
    "    conv3 = Conv2D(256, 5,  padding = 'same', strides=(2, 2), activation = 'relu')(conv2)\n",
    "    conv3_1 = Conv2D(256, 3, padding = 'same', strides=(1, 1), activation = 'relu')(conv3)\n",
    "    conv4 = Conv2D(512, 3,  padding = 'same', strides=(2, 2), activation = 'relu')(conv3_1)\n",
    "    conv4_1 = Conv2D(512, 3,  padding = 'same', strides=(1, 1), activation = 'relu')(conv4)\n",
    "    conv5 = Conv2D(512, 3,  padding = 'same', strides=(2, 2), activation = 'relu')(conv4_1)\n",
    "    conv5_1 = Conv2D(512, 3, padding = 'same', strides=(1, 1), activation = 'relu')(conv5)\n",
    "    \n",
    "    deconv5 = Conv2D(512, 3, padding = 'same', use_bias=False, strides=(1, 1), activation = 'relu')(UpSampling2D(size = (2,2), interpolation = 'bilinear')(conv5_1))\n",
    "    deconv4 = Conv2D(256, 3, padding = 'same', use_bias=False, strides=(1, 1), activation = 'relu')(UpSampling2D(size = (2,2), interpolation = 'bilinear')(deconv5))\n",
    "    merge4 = concatenate([deconv4,conv3], axis = 3)    \n",
    "    aux3 = Conv2D(1, 3, padding = 'same', use_bias =False, strides=(1, 1), activation = 'sigmoid')(merge4)\n",
    "    deconv3 = Conv2D(128, 3, padding = 'same', use_bias=False, strides=(1, 1), activation = 'relu')(UpSampling2D(size = (2,2), interpolation = 'bilinear')(merge4))\n",
    "    merge3 = concatenate([deconv3,conv2], axis = 3)\n",
    "    aux2 = Conv2D(1, 3, padding = 'same', use_bias =False, strides=(1, 1), activation = 'sigmoid')(merge3)\n",
    "    deconv2 = Conv2D(64, 3, padding = 'same', use_bias=False, strides=(1, 1), activation = 'relu')(UpSampling2D(size = (2,2), interpolation = 'bilinear')(merge3))\n",
    "    merge2 = concatenate([deconv2,conv1], axis = 3)\n",
    "    aux1 = Conv2D(1, 3, padding = 'same', use_bias =False, strides=(1, 1), activation = 'sigmoid')(merge2)\n",
    "    deconv1 = Conv2D(64, 3, padding = 'same', use_bias=False, strides=(1, 1), activation = 'relu')(UpSampling2D(size = (2,2), interpolation = 'bilinear')(merge2))\n",
    "    output = Conv2D(1, 3, activation = 'sigmoid', padding = 'same')(deconv1)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = [output, aux1, aux2, aux3])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_input = Input(shape=(256,256,3))\n",
    "model = generator(gen_input)\n",
    "model.compile(optimizer = Adam(lr = 0.0002), loss = ['mse','mse','mse','mse'], loss_weights = [0.64, 0.16, 0.04, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model('checkpoints/cv_sc_epochs12.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/data1/depth/endo_sim2/train/'\n",
    "batch = 32\n",
    "train = data_generator(train_path, batch, 1)\n",
    "val_path = '/data1/depth/endo_sim2/val/'\n",
    "batch = 32\n",
    "val = data_generator(val_path, batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(train_path)\n",
    "train_img_list = []\n",
    "for j in dir_list:\n",
    "    img_path = os.path.join(train_path, j)\n",
    "    tmp_list = sorted(glob.glob(img_path +'/*.png'))\n",
    "    train_img_list += tmp_list\n",
    "    \n",
    "print(len(train_img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 10\n",
    "steps = int(np.ceil(len(train_img_list)/batch))\n",
    "epochs = 16\n",
    "\n",
    "total_loss = []\n",
    "val_total_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step in range(steps):\n",
    "        train_img, train_lab = next(train)\n",
    "        loss = model.train_on_batch(train_img, train_lab)\n",
    "    total_loss.append(loss[0])\n",
    "    val_img, val_lab = next(val)\n",
    "    val_loss = model.evaluate(val_img, val_lab)\n",
    "    \n",
    "    val_total_loss.append(val_loss[0])\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    clear_output(wait=True)\n",
    "    val_p = model.predict(val_img)\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.subplot(211)\n",
    "    plt.plot(total_loss,'.-')\n",
    "    plt.plot(val_total_loss,'.-')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "    plt.subplot(234)\n",
    "    plt.imshow(val_img[0])\n",
    "    plt.title(\"input\")\n",
    "    plt.subplot(235)\n",
    "    plt.imshow(1-np.reshape(val_p[0][0]*scale, (256,256)), cmap = 'viridis')\n",
    "    plt.title(\"predict images(val)\")\n",
    "    plt.subplot(236)\n",
    "    plt.imshow(1-np.reshape(val_lab[0][0]*scale, (256,256)), cmap = 'viridis')\n",
    "    plt.title(\"label\")\n",
    "    plt.show()\n",
    "    if epoch % 5 == 0:\n",
    "        model_path = \"test_%s_%02d_%.2f\"%(model_name, epoch, loss)\n",
    "        model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 2\n",
    "\n",
    "test_img, test_lab= next(val)\n",
    "test_p = model.predict(test_img)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(141)\n",
    "plt.imshow(test_img[0])\n",
    "plt.title(\"input\")\n",
    "plt.subplot(142)\n",
    "plt.imshow(1-np.reshape(test_p[0][0]*scale,(256,256)),vmin = 0, vmax = 1, cmap = 'viridis')\n",
    "plt.title(\"val predict images(scaling)\")\n",
    "plt.subplot(143)\n",
    "plt.imshow(1-np.reshape(test_lab[0][0]*scale,(256,256)),vmin = 0, vmax = 1, cmap = 'viridis')\n",
    "plt.title(\"label(scaling)\")\n",
    "plt.subplot(144)\n",
    "plt.imshow(1-np.reshape(test_lab[0][0], (256,256)),vmin = 0, vmax = 1, cmap = 'viridis')\n",
    "plt.title(\"label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/data1/depth/endo_sim2/test/'\n",
    "batch = 32\n",
    "test = data_generator(test_path, batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 2\n",
    "for i in range(10):\n",
    "    test_img, test_lab= next(test)\n",
    "    test_p = model.predict(test_img)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(141)\n",
    "    plt.imshow(test_img[0])\n",
    "    plt.title(\"input\")\n",
    "    plt.subplot(142)\n",
    "    plt.imshow(1-np.reshape(test_p[0][0]*scale,(256,256)),vmin = 0, vmax = 1, cmap = 'viridis')\n",
    "    plt.title(\"test predict images(scaling)\")\n",
    "    plt.subplot(143)\n",
    "    plt.imshow(1-np.reshape(test_lab[0][0]*scale,(256,256)),vmin = 0, vmax = 1, cmap = 'viridis')\n",
    "    plt.title(\"label(scaling)\")\n",
    "    plt.subplot(144)\n",
    "    plt.imshow(1-np.reshape(test_lab[0][0], (256,256)),vmin = 0, vmax = 1, cmap = 'viridis')\n",
    "    plt.title(\"label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import compare_mse as mse\n",
    "from skimage.measure import compare_nrmse as nrmse\n",
    "from skimage.measure import compare_psnr as psnr\n",
    "from skimage.measure import compare_ssim as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrmse_ = []\n",
    "mse_ = []\n",
    "psnr_ = []\n",
    "ssim_ = []\n",
    "\n",
    "for i in range(100):\n",
    "    test_img, test_lab= next(test)\n",
    "    tmp_test = model.predict(test_img)\n",
    "    tmp_test = tmp_test[0][0]\n",
    "    tmp_test = tmp_test.astype('float64')\n",
    "    nrmse_.append(nrmse(tmp_test, test_lab[0][0]))\n",
    "    mse_.append(mse(tmp_test, test_lab[0][0]))\n",
    "    psnr_.append(psnr(tmp_test, test_lab[0][0]))\n",
    "    ssim_.append(ssim(tmp_test, test_lab[0][0], multichannel=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rmse : ', np.array(nrmse_).mean())\n",
    "print('mse : ', np.array(mse_).mean())\n",
    "print('psnr : ', np.array(psnr_).mean())\n",
    "print('ssim : ', np.array(ssim_).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data1/depth/endo/endo/endo_ori/train/'\n",
    "dir_list = os.listdir(path)\n",
    "dir_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_list = []\n",
    "for j in dir_list:\n",
    "    frame_list = glob.glob(os.path.join(path, j, '*.png'))\n",
    "    total_list += frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_list = random.sample(total_list, 10)\n",
    "for tmp in rand_list:\n",
    "    img = np.expand_dims(cv2.resize(np.array(Image.open(tmp))/255., (256,256)), axis=0)\n",
    "    test_p = model.predict(img)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img[0])\n",
    "    plt.title(\"input\")\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(1-np.reshape(test_p[0][0]*scale,(256,256)),vmin = 0, vmax = 1, cmap = 'viridis')\n",
    "    plt.title(\"predict images(test)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data1/GIANA/Detection/jerry/raw_image/'\n",
    "dir_list = os.listdir(path)\n",
    "dir_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_list = glob.glob(os.path.join(path, '*.png'))\n",
    "rand_list = random.sample(frame_list, 10)\n",
    "for tmp in rand_list:\n",
    "    img = np.expand_dims(cv2.resize(np.array(Image.open(tmp))/255., (256,256)), axis=0)\n",
    "    test_p = model.predict(img)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img[0])\n",
    "    plt.title(\"input\")\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(np.reshape(1- test_p[0][0]*scale,(256,256)),vmin = 0, vmax = 1, cmap = 'viridis')\n",
    "    plt.title(\"predict images(test)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cv_cv_aux1_epochs25.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
